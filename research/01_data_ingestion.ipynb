{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf831f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d1fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\syama talari\\\\OneDrive\\\\Desktop\\\\model_deployement_mlops\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5060df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a02448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\syama talari\\\\OneDrive\\\\Desktop\\\\model_deployement_mlops'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2ba5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingPipelineConfig:\n",
    "    root_dir : Path\n",
    "    source_URL : str\n",
    "    local_data_file : Path\n",
    "    unzip_dir : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104df854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlproj.constants import *\n",
    "from mlproj.utils.common import read_yaml\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from mlproj import logger\n",
    "from mlproj.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6506706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path_to_directory: Path) -> None: # <-- FIX IS HERE\n",
    "    \"\"\"Creates a directory if it does not exist.\"\"\"\n",
    "    os.makedirs(path_to_directory, exist_ok=True)\n",
    "    logger.info(f\"Directory created at: {path_to_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42158498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH,\n",
    "        schema_filepath: Path = SCHEMA_FILE_PATH,\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directory(Path(self.config.artifacts_root))\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> TrainingPipelineConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        data_ingestion_config = TrainingPipelineConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=Path(config.local_data_file),\n",
    "            unzip_dir=Path(config.unzip_dir),\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ede192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: TrainingPipelineConfig):\n",
    "        self.config = config\n",
    "        # Ensure the root directory for ingestion exists\n",
    "        # You should have created artifacts/data_ingestion earlier, but creating it here adds robustness\n",
    "        os.makedirs(self.config.root_dir, exist_ok=True) \n",
    "\n",
    "    # We modify download_data to be more generic and handle both local/remote\n",
    "    def download_or_copy_data(self) -> Path:\n",
    "        source_url = self.config.source_URL\n",
    "        dest_path = self.config.local_data_file\n",
    "\n",
    "        # 1. Handle Remote Download (e.g., starts with http)\n",
    "        if source_url.lower().startswith('http'):\n",
    "            if not os.path.exists(dest_path):\n",
    "                # Ensure local directory for saving the file exists\n",
    "                os.makedirs(dest_path.parent, exist_ok=True) \n",
    "\n",
    "                filename, headers = request.urlretrieve(\n",
    "                    url = source_url,\n",
    "                    filename = dest_path\n",
    "                )\n",
    "                logger.info(f\"Remote file: {filename} downloaded successfully.\")\n",
    "            else:\n",
    "                logger.info(f\"Remote file already exists.\")\n",
    "\n",
    "        # 2. Handle Local Copy (if source_URL is a local file path)\n",
    "        elif os.path.exists(source_url):\n",
    "            # The destination path needs its parent directory created first\n",
    "            os.makedirs(dest_path.parent, exist_ok=True) \n",
    "            \n",
    "            # Use shutil.copy to copy the CSV file locally\n",
    "            shutil.copy(source_url, dest_path)\n",
    "            logger.info(f\"Local file copied from {source_url} to {dest_path}\")\n",
    "            \n",
    "        else:\n",
    "            logger.error(f\"Source URL/Path is invalid or does not exist: {source_url}\")\n",
    "            raise FileNotFoundError(f\"Data source not found at {source_url}\")\n",
    "\n",
    "        return dest_path\n",
    "    \n",
    "    # We rename this to reflect the unzipping step which may not always be needed\n",
    "    def extract_if_zip(self, file_path: Path, extract_to: Path) -> None:\n",
    "        if file_path.suffix == '.zip':\n",
    "            # This is your existing unzip logic, only run for zip files\n",
    "            os.makedirs(extract_to, exist_ok=True)\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_to)\n",
    "            logger.info(f\"File extracted to: {extract_to}\")\n",
    "        else:\n",
    "            # If it's not a zip (e.g., CSV), the extraction step is essentially complete\n",
    "            logger.info(f\"File {file_path} is not a zip; skipping extraction step.\")\n",
    "            # For a CSV, the data is now in local_data_file, which is the final path\n",
    "\n",
    "    def initiate_data_ingestion(self) -> Path:\n",
    "        # Step 1: Download or Copy the data\n",
    "        ingested_file_path = self.download_or_copy_data()\n",
    "        \n",
    "        # Step 2: Extract the data (Only runs if it's a zip)\n",
    "        self.extract_if_zip(ingested_file_path, self.config.unzip_dir)\n",
    "        \n",
    "        # We need to return the path to the actual CSV file.\n",
    "        # Since you are likely copying a CSV file, the final data path is usually the local_data_file.\n",
    "        return self.config.unzip_dir # If unzipped, or local_data_file if copied CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afc9fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-28 22:36:40,218: INFO: common]: YAML file: configs\\config.yaml loaded successfully]\n",
      "[2025-10-28 22:36:40,221: INFO: common]: YAML file: params.yaml loaded successfully]\n",
      "[2025-10-28 22:36:40,224: INFO: common]: YAML file: schema.yaml loaded successfully]\n",
      "[2025-10-28 22:36:40,227: INFO: 3425958059]: Directory created at: artifacts]\n",
      "[2025-10-28 22:36:41,629: INFO: 2876475998]: Remote file: artifacts\\data_ingestion\\data.zip downloaded successfully.]\n",
      "[2025-10-28 22:36:41,671: INFO: 2876475998]: File extracted to: artifacts\\data_ingestion]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.initiate_data_ingestion()\n",
    "except Exception as e:\n",
    "    logger.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2df0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
